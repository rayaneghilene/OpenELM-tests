{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMPmz5fBnhMl2HfT7x6E9X9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rayaneghilene/OpenELM-tests/blob/main/OpenELM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apple OpenELM text generation"
      ],
      "metadata": {
        "id": "dELJLxmhXLLG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install the latest version of transformers from Github"
      ],
      "metadata": {
        "id": "z-XOYE82X1_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/huggingface/transformers.git@main"
      ],
      "metadata": {
        "id": "23-qIDrzXx6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hugginface login"
      ],
      "metadata": {
        "id": "YWGHPKCMaBlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izqnIJ62aDkQ",
        "outputId": "d41e720c-d1fd-4365-ce55-5d8b49466573"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/huggingface-cli\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/commands/huggingface_cli.py\", line 49, in main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/commands/user.py\", line 98, in run\n",
            "    login(token=self.args.token, add_to_git_credential=self.args.add_to_git_credential)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/_login.py\", line 113, in login\n",
            "    interpreter_login(new_session=new_session, write_permission=write_permission)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/_login.py\", line 189, in interpreter_login\n",
            "    token = getpass(\"Token: \")\n",
            "  File \"/usr/lib/python3.10/getpass.py\", line 77, in unix_getpass\n",
            "    passwd = _raw_input(prompt, stream, input=input)\n",
            "  File \"/usr/lib/python3.10/getpass.py\", line 146, in _raw_input\n",
            "    line = input.readline()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenELM-270M"
      ],
      "metadata": {
        "id": "_hwfPOU_X-I5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\", trust_remote_code=True)\n",
        "pipe = pipeline(\"text-generation\", model=\"apple/OpenELM-270M-Instruct\",  tokenizer=tokenizer, trust_remote_code=True)"
      ],
      "metadata": {
        "id": "UJed9urhXHt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_prompt = \"Write a short story about a mysterious island hidden in the fog.\"\n",
        "pipe(custom_prompt)#, do_sample=False)"
      ],
      "metadata": {
        "id": "6sYZvo1fXRTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenELM-450M"
      ],
      "metadata": {
        "id": "cgza1a7IY34q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\", trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\"apple/OpenELM-270M-Instruct\", trust_remote_code=True)"
      ],
      "metadata": {
        "id": "kuCJpJKuY8cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_prompt = \"Write a short story about a mysterious island hidden in the fog.\"\n",
        "pipe(custom_prompt)#, do_sample=False)"
      ],
      "metadata": {
        "id": "OuB_WtZbS09A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}